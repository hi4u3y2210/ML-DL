{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料為flyingV是爬文而得\n",
    "本程式先將各成功募款文章用kmeans分群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, datasets\n",
    "from sklearn.cluster import KMeans\n",
    "import jieba\n",
    "import csv\n",
    "import numpy as np\n",
    "punc = [\"』\",\"『\",\"丨\",\"｜\",\"|\",\"│\",\"─\",\"｜\",\"－\",\"—\",\"〉\",\"〈\",\">\",\"<\",\"&\", \"]\", \"[\", \"╱\", \"/\", \"0\",\"０\",\"1\",\"１\",\"2\",\"２\",\"3\",\"３\",\"4\",\"４\",\"5\",\"５\",\"6\",\"６\",\"7\",\"７\",\"8\",\"８\",\"9\",\"９\",\"。\",\".\",\"；\",\"=\",\"●\",\"%\",\"【\",\"】\",\"《\",\"》\",\"：\",\":\",\"+\",\"?\",\"？\",\"!\",\"！\",\"，\",\",\" ,\"「\",\"　\",\"」\",\"＊\",\"’\",'\"', \" \",\"(\",\")\",\"（\",\"）\",\"-\",\"／\",\"、\"]\n",
    "jieba.set_dictionary('C:\\Program Files\\Python36\\lib\\site-packages\\jieba\\dict.txt.big.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "with open('stoplist.txt', 'r', encoding='utf8') as txtFile:\n",
    "    for data in txtFile.readlines():\n",
    "        data = data.strip()\n",
    "        stopwords.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {}\n",
    "dic = {}\n",
    "count_row = 0\n",
    "count_corpus = 0\n",
    "temp_cors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Program Files\\Python36\\lib\\site-packages\\jieba\\dict.txt.big.txt ...\n",
      "Loading model from cache C:\\Users\\ucer\\AppData\\Local\\Temp\\jieba.ufdf3adf8ca174fd60fd39d3555294534.cache\n",
      "Loading model cost 1.407 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "with open(\"flyingV_money (1).csv\", \"r\", encoding=\"utf16\") as csvFile:\n",
    "    rows = csv.DictReader(csvFile, delimiter = \"\\t\")\n",
    "    for row in rows:\n",
    "        dic[count_row] = []\n",
    "        temp_title = \"\"\n",
    "        for temp_word in row[\"title\"]:\n",
    "            if temp_word in punc:\n",
    "                continue\n",
    "            temp_title += temp_word\n",
    "        words = jieba.cut(temp_title)\n",
    "        if row[\"money\"] < row[\"targetmoney\"]:\n",
    "            continue\n",
    "        for word in words:\n",
    "            if word not in stopwords:\n",
    "                dic[count_row].append(word)\n",
    "                if word not in corpus:\n",
    "                    temp_cors.append(word)\n",
    "                    corpus[word] = 1\n",
    "                    count_corpus += 1\n",
    "                else: \n",
    "                    corpus[word] += 1\n",
    "        count_row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "# Y = [0] * count_corpus\n",
    "# X = []\n",
    "# for row in range(count_row):\n",
    "#     X.append(Y)\n",
    "\n",
    "\n",
    "df_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in temp_cors:\n",
    "    temp = []\n",
    "    for article in dic:\n",
    "        if word in dic[article]:\n",
    "            temp.append(article)\n",
    "    df_dic[word] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in df_dic:\n",
    "    temp = []\n",
    "    for article in dic:\n",
    "        if word in dic[article]:\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    X.append(temp)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分群結果：\n",
      "[1 1 1 ... 2 2 1]\n",
      "---\n",
      "分群結果：\n",
      "[3 3 3 ... 0 0 3]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "K = [3, 5]\n",
    "# KMeans 演算法\n",
    "for k in K:\n",
    "    kmeans_fit = cluster.KMeans(n_clusters = k).fit(X.T)\n",
    "\n",
    "    # 印出分群結果\n",
    "    cluster_labels = kmeans_fit.labels_\n",
    "    print(\"分群結果：\")\n",
    "    print(cluster_labels)\n",
    "    print(\"---\")\n",
    "\n",
    "    np.savetxt(str(k) + \"_result(success).txt\", cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
